{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35bf6e4c-fe21-4723-a8f0-d524dbc49ddd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Since you are operating in a Session-Based Architecture (without a central Metastore/Catalog), you cannot simply go to the \"Catalog\" tab or run standard SELECT * FROM table commands in the SQL Editor. The tables \"physically\" exist in S3, but the Databricks UI doesn't know they exist.\n",
    "\n",
    "To query them, you must register them as Temporary Views inside your notebook. This bridges the gap between your Python credentials and SQL syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "700f8e65-7098-49fb-afd6-de588a759484",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ACCESS_KEY = dbutils.secrets.get(scope = \"ticker\", key = \"access_key\")\n",
    "SECRET_KEY = dbutils.secrets.get(scope = \"ticker\", key = \"secret_key\")\n",
    "SESSION_TOKEN = dbutils.secrets.get(scope = \"ticker\", key = \"session_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ae17667-0103-4622-a481-4bb32a7bcbc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Setup Credentials (As always)\n",
    "ACCESS_KEY = dbutils.secrets.get(scope = \"ticker\", key = \"access_key\")\n",
    "SECRET_KEY = dbutils.secrets.get(scope = \"ticker\", key = \"secret_key\")\n",
    "SESSION_TOKEN = dbutils.secrets.get(scope = \"ticker\", key = \"session_key\")\n",
    "\n",
    "# 2. Define Source Paths (S3)\n",
    "bronze_path = \"s3a://mzon-to-databricks-5482/bronze/source=fmp/\"\n",
    "silver_path = \"s3a://mzon-to-databricks-5482/silver/income_statement/valid\"\n",
    "quarantine_path = \"s3a://mzon-to-databricks-5482/quarantine/company_financials/\"\n",
    "\n",
    "# 3. Define the Secure Reader\n",
    "def read_secure(path):\n",
    "    return (spark.read.format(\"delta\")\n",
    "            .option(\"fs.s3a.access.key\", ACCESS_KEY)\n",
    "            .option(\"fs.s3a.secret.key\", SECRET_KEY)\n",
    "            .option(\"fs.s3a.session.token\", SESSION_TOKEN)\n",
    "            .option(\"fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider\")\n",
    "            .load(path))\n",
    "\n",
    "# 4. The \"Snapshot\" Logic\n",
    "# We read from S3 (Secure) -> Write to Managed Table (Open)\n",
    "def refresh_managed_table(table_name, s3_path):\n",
    "    try:\n",
    "        print(f\"ðŸ”„ Syncing {table_name} from S3...\")\n",
    "        df = read_secure(s3_path)\n",
    "        \n",
    "        # Overwrite the Managed Table (Saves to DBFS/Local)\n",
    "        # This makes it queryable via SQL without keys!\n",
    "        df.write.mode(\"overwrite\").saveAsTable(table_name)\n",
    "        \n",
    "        print(f\"âœ… Success! Table '{table_name}' is now live in Catalog.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Could not sync {table_name}. (Data might not exist yet). Error: {e}\")\n",
    "\n",
    "# 5. Execute Sync\n",
    "refresh_managed_table(\"bronze_audit\", bronze_path)\n",
    "refresh_managed_table(\"silver_audit\", silver_path)\n",
    "refresh_managed_table(\"quarantine_audit\", quarantine_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b67efc2-8b14-4706-bd9e-0e62d6f06716",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "A. Check Bronze (Raw History)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eada3d3f-b992-45c7-b3dc-0bb816b8c464",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 1. How many raw records do we have?\n",
    "SELECT count(*) as total_bronze_rows FROM v_bronze;\n",
    "\n",
    "-- 2. Do we have duplicates? (Should be YES if you ran the job twice)\n",
    "SELECT symbol, date, count(*) as duplicate_count  , eps\n",
    "FROM v_bronze \n",
    "GROUP BY symbol, date ,eps\n",
    "HAVING count(*) > 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8d3901e-20cd-43ea-a88d-5e4f6cbb84aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "B. Check Silver (The \"Truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b46cf108-571e-4a26-bd2f-cf681625fa71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 1. Verify Uniqueness (Should return 0 rows)\n",
    "SELECT symbol, date, count(*) \n",
    "FROM v_silver \n",
    "GROUP BY symbol, date \n",
    "HAVING count(*) > 1;\n",
    "\n",
    "-- 2. Check Data Types & Values\n",
    "SELECT symbol, date, revenue, eps, reportedCurrency\n",
    "FROM v_silver\n",
    "ORDER BY date DESC\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19e6fd29-8e21-4778-843f-e9541302796d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 1. Why are rows failing?\n",
    "SELECT date, symbol, _failed_cols, revenue, eps\n",
    "FROM v_quarantine\n",
    "LIMIT 20;\n",
    "\n",
    "-- 2. Which error is most common?\n",
    "SELECT _failed_cols, count(*) as error_count\n",
    "FROM v_quarantine\n",
    "GROUP BY _failed_cols;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6500674566605065,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Query Bronze and silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
