{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35bf6e4c-fe21-4723-a8f0-d524dbc49ddd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Since you are operating in a Session-Based Architecture (without a central Metastore/Catalog), you cannot simply go to the \"Catalog\" tab or run standard SELECT * FROM table commands in the SQL Editor. The tables \"physically\" exist in S3, but the Databricks UI doesn't know they exist.\n",
    "\n",
    "To query them, you must register them as Temporary Views inside your notebook. This bridges the gap between your Python credentials and SQL syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "700f8e65-7098-49fb-afd6-de588a759484",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ACCESS_KEY = dbutils.secrets.get(scope = \"ticker\", key = \"access_key\")\n",
    "SECRET_KEY = dbutils.secrets.get(scope = \"ticker\", key = \"secret_key\")\n",
    "SESSION_TOKEN = dbutils.secrets.get(scope = \"ticker\", key = \"session_key\")\n",
    "\n",
    "temp_ak = dbutils.jobs.taskValues.get(taskKey=\"Init_Auth\", key=\"temp_ak\", debugValue=\"debug-key\")\n",
    "temp_sk = dbutils.jobs.taskValues.get(taskKey=\"Init_Auth\", key=\"temp_sk\", debugValue=\"debug-secret\")\n",
    "temp_token = dbutils.jobs.taskValues.get(taskKey=\"Init_Auth\", key=\"temp_token\", debugValue=\"debug-token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ae17667-0103-4622-a481-4bb32a7bcbc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "aws_creds = {\n",
    "    \"fs.s3a.access.key\": ACCESS_KEY,\n",
    "    \"fs.s3a.secret.key\": SECRET_KEY,\n",
    "    \"fs.s3a.session.token\": SESSION_TOKEN,\n",
    "    \"fs.s3a.aws.credentials.provider\": \"org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider\"\n",
    "}\n",
    "\n",
    "# 2. Define Table Registry (Single Source of Truth)\n",
    "# Maps the Managed Table Name -> The S3 Source Path\n",
    "sync_config = [\n",
    "  \n",
    "     {\n",
    "        \"table_name\": \"gold_valid_audit\",\n",
    "        \"s3_path\": \"s3a://mzon-to-databricks-5482/gold/valid\",\n",
    "        \"partition_col\": \"date\"\n",
    "    },\n",
    "      {\n",
    "        \"table_name\": \"gold_quarantine_audit\",\n",
    "        \"s3_path\": \"s3a://mzon-to-databricks-5482/gold/invalid\",\n",
    "        \"partition_col\": \"date\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 3. The Optimized Sync Function\n",
    "def sync_s3_to_managed(table_config):\n",
    "    table_name = table_config[\"table_name\"]\n",
    "    path = table_config[\"s3_path\"]\n",
    "    part_col = table_config.get(\"partition_col\")\n",
    "\n",
    "    try:\n",
    "        print(f\"ðŸ”„ Syncing {table_name}...\")\n",
    "        \n",
    "        # READ (Securely from S3)\n",
    "        df = (spark.read.format(\"delta\")\n",
    "              .options(**aws_creds)\n",
    "              .load(path))\n",
    "\n",
    "        # WRITE (To Managed Table)\n",
    "        # OPTIMIZATION: We add .partitionBy() to ensure the managed table \n",
    "        # has the exact same physical structure as S3.\n",
    "        writer = df.write.mode(\"overwrite\").format(\"delta\")\n",
    "        \n",
    "        if part_col:\n",
    "            writer = writer.partitionBy(part_col)\n",
    "            \n",
    "        writer.saveAsTable(table_name)\n",
    "        \n",
    "        print(f\"Success: {table_name} synced with partitioning on '{part_col}'.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipped {table_name}: {str(e)}\")\n",
    "\n",
    "# 4. Execute Loop\n",
    "for config in sync_config:\n",
    "    sync_s3_to_managed(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c4b90ba-685a-492b-90da-8866687fc7d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from gold_quarantine_audit"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8138043807909371,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Query Bronze and silver",
   "widgets": {
    "vacuum_retention_days": {
     "currentValue": "14",
     "nuid": "cd4fd4df-6606-4af0-b9f2-d736364d7b01",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "14",
      "label": "Vacuum Retention (Days)",
      "name": "vacuum_retention_days",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "14",
      "label": "Vacuum Retention (Days)",
      "name": "vacuum_retention_days",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
