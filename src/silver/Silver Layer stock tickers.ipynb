{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d8ac713-7b58-443d-b267-983551d65f1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import ArrayType , StringType , StructField , StructType , LongType , DoubleType , IntegerType , BooleanType\n",
    "from pyspark.sql.window import Window\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8b34013-0e62-4334-9d47-d98a1032450e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "source_path = \"/Volumes/workspace/default/storage/bronze/ticker_data_v2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "860a92f6-c1f3-40ac-a6db-fd4a995f25a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# providing a starting version\n",
    "df = spark.readStream.format(\"delta\") \\\n",
    "  .option(\"startingVersion\", \"0\") \\\n",
    "  .load(source_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d3f84d9-8cc9-4145-bdd1-fb489f974185",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9736efd2-abbf-4e3b-8095-1040697a1868",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # --- 2. PARSE MINIMAL DATA ---\n",
    "# # We only need Ticker and Timestamp to check frequency\n",
    "# schema = StructType([\n",
    "#     StructField(\"s\", StringType(), True),\n",
    "#     StructField(\"timestamp\", LongType(), True)\n",
    "# ])\n",
    "\n",
    "# # Handle the Base64/Binary casting we discussed\n",
    "# df = df.withColumn(\"json_str\", F.col(\"value\").cast(\"string\")) \\\n",
    "#        .select(F.from_json(\"json_str\", schema).alias(\"data\")) \\\n",
    "#        .select(\"data.*\")\n",
    "\n",
    "# # --- 3. CALCULATE GAPS ---\n",
    "# # We verify if your timestamp is Seconds or Milliseconds dynamically\n",
    "# # If the average gap is ~15, it's seconds. If it's ~15000, it's millis.\n",
    "# df = df.filter(\"s = 'SPY'\") \\\n",
    "#        .withColumn(\"prev_ts\", F.lag(\"timestamp\").over(Window.orderBy(\"timestamp\"))) \\\n",
    "#        .withColumn(\"gap\", F.col(\"timestamp\") - F.col(\"prev_ts\"))\n",
    "\n",
    "# df_tickers = df.filter(\"s != 'SPY'\") \\\n",
    "#        .withColumn(\"prev_ts\", F.lag(\"timestamp\").over(Window.orderBy(\"timestamp\"))) \\\n",
    "#        .withColumn(\"gap\", F.col(\"timestamp\") - F.col(\"prev_ts\"))\n",
    "\n",
    "# # --- 4. SHOW STATISTICS ---\n",
    "# print(\"--- FREQUENCY ANALYSIS (SPY) ---\")\n",
    "# print(\"Units: Raw Timestamp Units (likely Seconds)\")\n",
    "# df.select(\"gap\").summary(\"count\", \"min\", \"25%\", \"50%\", \"75%\", \"max\", \"mean\").show()\n",
    "\n",
    "# print(\"shopw statistics for al ltickers\")\n",
    "# df_tickers.select(\"gap\").summary(\"count\", \"min\", \"25%\", \"50%\", \"75%\", \"max\", \"mean\").show()\n",
    "# # --- 5. VISUALIZE THE PATTERN ---\n",
    "# print(\"--- LATEST 10 GAPS ---\")\n",
    "# df.select(\"timestamp\", \"prev_ts\", \"gap\").orderBy(F.col(\"timestamp\").desc()).show(10)\n",
    "\n",
    "# df_tickers.select(\"timestamp\", \"prev_ts\", \"gap\").orderBy(F.col(\"timestamp\").desc()).show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a2c0e25-d105-4af8-8b34-e94989eea3d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"s\", StringType(), True),\n",
    "     StructField(\"currentPrice\", DoubleType(), True),\n",
    "     StructField(\"change\", DoubleType(), True),\n",
    "     StructField(\"changePercent\", DoubleType(), True),\n",
    "     StructField(\"high\", DoubleType(), True),\n",
    "     StructField(\"low\", DoubleType(), True),\n",
    "     StructField(\"open\", DoubleType(), True),\n",
    "     StructField(\"previousClose\", DoubleType(), True),\n",
    "      \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba8319de-58b6-4dc1-a711-4c652376b6de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\", \"topic\", \"partition\", \"offset\", \"timestamp\")\n",
    "df = df.withColumn(\"ticker\" , F.from_json(F.col(\"value\"), schema,options={\"mode\": \"PERMISSIVE\", \"columnNameOfCorruptRecord\": \"_corrupt_record\"}))\n",
    "df =df.select(\"ticker.*\" , F.col(\"timestamp\").alias(\"event_time\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f60b0947-f73b-4033-83b0-5a4c6e933d6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df = df.filter(\"changePercent IS NOT NULL AND changePercent != 0\")\n",
    "\n",
    "\n",
    "# df_market = df.filter(\"s = 'SPY'\") \\\n",
    "#               .selectExpr(\"changePercent as m_return\" , \"CAST(event_time as TIMESTAMP) as m_event_time\") \\\n",
    "#                    .withColumn(\"m_join_key\", F.lit(1)) \\\n",
    "#               .withWatermark(\"m_event_time\", \"2 minutes\")\n",
    "\n",
    "# df_tickers = df.filter(\"s != 'SPY'\") \\\n",
    "#                .withColumn(\"join_key\", F.lit(1)) \\\n",
    "#                 .withWatermark(\"event_time\", \"2 minutes\")\n",
    "\n",
    "# join_condition = (\n",
    "#     F.col(\"m_join_key\") == F.col(\"join_key\")\n",
    "# ) & (\n",
    "#     F.col(\"event_time\") >= F.col(\"m_event_time\") - F.expr(\"INTERVAL 2 MINUTES\")\n",
    "# ) & (\n",
    "#     F.col(\"event_time\") <= F.col(\"m_event_time\") + F.expr(\"INTERVAL 2 MINUTES\")\n",
    "# )\n",
    "\n",
    "# df = df_tickers.join(df_market, join_condition , \"inner\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ea79a3d-75f2-46f8-bae5-730b6168db4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_result = (df.groupBy(\n",
    "#                 F.col(\"s\"),\n",
    "#                 F.window(\"event_time\", \"10 minutes\")\n",
    "#             )\n",
    "#             .agg(\n",
    "#                 # The Beta Logic\n",
    "#                 (F.covar_samp(\"changePercent\", \"m_return\") / F.var_samp(\"m_return\")).alias(\"beta\"),\n",
    "                \n",
    "#                 # The \"Missing\" Columns - We must aggregate them\n",
    "#                 F.first(\"open\").alias(\"open_price\"),\n",
    "#                 F.max(\"high\").alias(\"high_price\"),\n",
    "#                 F.min(\"low\").alias(\"low_price\"),\n",
    "#                 F.last(\"currentPrice\").alias(\"close_price\"),\n",
    "#                 F.count(\"s\").alias(\"tick_count\")\n",
    "#             ))\n",
    "\n",
    "# df_result = df.groupBy(\"s\", F.window(\"event_time\", \"10 minutes\")) \\\n",
    "#                      .agg(F.count(\"*\").alias(\"match_count\"))\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c21ec44b-09df-4cb2-b460-4f888e18d1f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ACCESS_KEY = dbutils.secrets.get(scope = \"ticker\", key = \"access_key\")\n",
    "SECRET_KEY = dbutils.secrets.get(scope = \"ticker\", key = \"secret_key\")\n",
    "SESSION_TOKEN = dbutils.secrets.get(scope = \"ticker\", key = \"session_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5145c30d-58ce-4185-aa80-a2ea1b023e35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "BUCKET = \"mzon-to-databricks-5482\"\n",
    "destination_path = \"/Volumes/workspace/default/storage/silver/ticker_data_v5\"\n",
    "# --- 2. THE FIX: PATH MUST INCLUDE THE VOLUME NAME ---\n",
    "# Path format: /Volumes/<catalog>/<schema>/<VOLUME_NAME>/<folder>\n",
    "# We added 'storage' because that is the volume we just created in SQL.\n",
    "checkpoint_path = \"/Volumes/workspace/default/storage/checkpoints/job_silver_ticker_checkpoint_v5\"\n",
    "\n",
    "print(f\"Streaming Strategy:\")\n",
    "print(f\"Checkpoint: {checkpoint_path}\")\n",
    "print(f\"Data (S3): {destination_path}\")\n",
    "\n",
    "# --- 3. WRITE STREAM ---\n",
    "df.writeStream \\\n",
    "    .format(\"delta\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .option(\"checkpointLocation\", checkpoint_path) \\\n",
    "    .option(\"fs.s3a.access.key\", ACCESS_KEY) \\\n",
    "    .option(\"fs.s3a.secret.key\", SECRET_KEY) \\\n",
    "    .option(\"fs.s3a.session.token\", SESSION_TOKEN) \\\n",
    "    .option(\"fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider\") \\\n",
    "    .trigger(availableNow=True) \\\n",
    "    .start(destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d565709d-5f70-4587-bb20-e7b38170c1e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %fs rm -r /Volumes/workspace/default/storage/checkpoints/job_silver_ticker_v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9b118c8-8a6f-46b3-b0a4-0e076cc67a0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %fs rm -r /Volumes/workspace/default/storage/silver/ticker_data_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67055cc7-0d3d-4d38-9420-ab9214d872b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # 1. DELETE EVERYTHING (The \"Double Tap\")\n",
    "# print(\"Deleting Checkpoint...\")\n",
    "# dbutils.fs.rm(\"/Volumes/workspace/default/storage/checkpoints/job_silver_ticker_v2\", True)\n",
    "\n",
    "# print(\"Deleting Silver Table...\")\n",
    "# dbutils.fs.rm(\"/Volumes/workspace/default/storage/silver/ticker_data_v2\", True)\n",
    "\n",
    "# # 2. VERIFY DELETION\n",
    "# # This MUST fail with \"java.io.FileNotFoundException\" or return False\n",
    "# # If it returns True, the deletion failed.\n",
    "# print(f\"Checkpoint Exists? {dbutils.fs.ls('/Volumes/workspace/default/storage/checkpoints/job_silver_ticker')}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Silver Layer stock tickers",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
