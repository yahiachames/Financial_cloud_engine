{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a935d41a-97ef-43da-a93a-944bc310efd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Ingestion Layer: Financial Data Acquisition\n",
    "\n",
    "**Objective**: Retrieve raw financial statements (Income, Balance Sheet, Cash Flow) from the Financial Modeling Prep (FMP) API.\n",
    "\n",
    "**Workflow**:\n",
    "1.  **Configuration**: Retrieve API keys and session tokens from Databricks Secrets.\n",
    "2.  **Extraction**: Iteratively query the FMP API for a defined list of tickers.\n",
    "3.  **Validation**: executing HTTP requests with error handling to capture and log failures.\n",
    "4.  **Storage**: Persist raw JSON responses to the Landing Zone (S3) for downstream processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d560cd23-b907-43dd-aaaa-87e8ea75d920",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "dbutils.widgets.text(\"run_date\", datetime.now().strftime(\"%Y-%m-%d\"),\"Run date\")\n",
    "run_date = dbutils.widgets.get(\"run_date\")\n",
    "\n",
    "APIKey = dbutils.secrets.get(scope = \"ticker\", key = \"financialmodelprep_token\")\n",
    "BaseUrl = \"https://financialmodelingprep.com\"\n",
    "TICKERS = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"NVDA\", \"META\", \"JPM\", \"V\", \"JNJ\",\"PG\"]\n",
    "# TICKERS = [\"AAPL\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf1f8ea0-2eba-4a3f-9b85-c46c7dd90b54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_ticker(ticker,run_date):\n",
    "    \"\"\"\n",
    "    Fetches financial statements for a specific ticker and prepares the data for S3 storage.\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): The stock symbol to query.\n",
    "        run_date (str): The date of the execution run, used for partitioning.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of dictionaries, each containing the file name, JSON data, and status code.\n",
    "              On failure, returns an error log record routed to the 'audit_failures' path.\n",
    "    \"\"\"\n",
    "    Income_statement_Query = f\"{BaseUrl}/stable/income-statement?symbol={ticker}&limit=5&period=quarter&apikey={APIKey}\"\n",
    "    Balance_sheet_statement_Query = f\"{BaseUrl}/stable/balance-sheet-statement?symbol={ticker}&limit=5&period=quarter&apikey={APIKey}\"\n",
    "    cashflow_statement_Query = f\"{BaseUrl}/stable/cash-flow-statement?symbol={ticker}&limit=5&period=quarter&apikey={APIKey}\"\n",
    "\n",
    "    urls = [Income_statement_Query,Balance_sheet_statement_Query,cashflow_statement_Query]\n",
    "  \n",
    "    filename = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    files = []\n",
    "    try:\n",
    "        for Query in urls:\n",
    "            response = requests.get(Query, timeout=10)\n",
    "            response.raise_for_status() # Raises an HTTPError for bad responses (4xx or 5xx) \n",
    "            data = response.json()\n",
    "            label = Query.split('/')[4].split('?')[0]\n",
    "\n",
    "            # Spark Partitioning Scheme: /source=fmp/ticker=<SYMBOL>/date=<DATE>/\n",
    "            file_name = f\"landing/source=fmp/ticker={ticker}/date={run_date}/statement={label}/{filename}.json\"\n",
    "            \n",
    "            json_data = json.dumps(data, indent=2)\n",
    "            files.append({\"file_name\": file_name, \"json_data\": json_data,\"status\" : response.status_code})\n",
    "        return files\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing ticker {ticker}: {e}\")\n",
    "        # Resilience Pattern: Route failures to a quarantine location for later analysis.\n",
    "        file_name = f\"landing/source=fmp/audit_failures/ticker={ticker}/date={run_date}/{filename}.json\"\n",
    "        status_code =  response.status_code if 'response' in locals() else 500\n",
    "        error_log = {\n",
    "            \"error\": str(e),\n",
    "            \"ticker\": ticker,\n",
    "            \"status_code\": status_code\n",
    "        }\n",
    "        return [{\"file_name\": file_name, \"json_data\": json.dumps(error_log,indent=2), \"status\" : status_code}]\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0cde2c6-ac3b-45db-8132-8374bd03cdb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "flat_list = []\n",
    "for ticker in TICKERS:\n",
    "    flat_list.extend(process_ticker(ticker,run_date))\n",
    "\n",
    "print(f\"Data collection complete. Total keys generated: {len(flat_list)}. Symbols found: {set([ticker['file_name'] if 'file_name' in ticker else None for ticker in flat_list])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea6409e8-6d1c-41df-8cbd-6e004d540ce6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### S3 Persistence Layer\n",
    "Establish a boto3 connection to S3 using temporary session credentials forwarded from the initialization task. This method ensures secure access without hardcoding long-term credentials in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dafcf42-ba83-4c8c-8ff8-6341647c024c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "ACCESS_KEY = dbutils.secrets.get(scope = \"ticker\", key = \"access_key\")\n",
    "SECRET_KEY = dbutils.secrets.get(scope = \"ticker\", key = \"secret_key\")\n",
    "SESSION_TOKEN = dbutils.secrets.get(scope = \"ticker\", key = \"session_key\")\n",
    "\n",
    "# \"taskKey\" must match the NAME of the task in your Job workflow (e.g., \"Init_Auth\")\n",
    "temp_ak = dbutils.jobs.taskValues.get(taskKey=\"Init_Auth\", key=\"temp_ak\", debugValue=\"debug-key\")\n",
    "temp_sk = dbutils.jobs.taskValues.get(taskKey=\"Init_Auth\", key=\"temp_sk\", debugValue=\"debug-secret\")\n",
    "temp_token = dbutils.jobs.taskValues.get(taskKey=\"Init_Auth\", key=\"temp_token\", debugValue=\"debug-token\")\n",
    "\n",
    "# Initialize S3 Client\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=temp_ak,\n",
    "    aws_secret_access_key=temp_sk,\n",
    "    aws_session_token=temp_token\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "for ticker in flat_list:\n",
    "    print(ticker['file_name'])\n",
    "\n",
    "    # 4. Specify your bucket name and the desired file name (key) in S3\n",
    "    bucket_name = 'arn:aws:s3:us-east-1:180250667274:accesspoint/accesspoint-to-data'\n",
    "    s3_object_key = ticker['file_name']\n",
    "\n",
    "    # 5. Upload the JSON string\n",
    "    s3.put_object(\n",
    "    Bucket=bucket_name,\n",
    "    Key=s3_object_key,\n",
    "    Body=ticker['json_data']\n",
    ")\n",
    "  \n",
    "\n",
    "    print(f\"Successfully uploaded JSON data to s3://{bucket_name}/{s3_object_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d67b5a1-0792-43c9-a52d-00cf16efb576",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Verification & Quality Assurance\n",
    "\n",
    "1.  **Resilience**: The pipeline traps exceptions during API calls and routes them to a dedicated `audit_failures` path, ensuring the batch does not fail partially.\n",
    "2.  **Observability**: Error logs preserve the exact error message and status code for debugging.\n",
    "3.  **Disaster Recovery**: The `run_date` widget enables execution for arbitrary historical dates, facilitating backfilling.\n",
    "4.  **Data Integrity**: Data is stored as valid JSON structures, ready for schema-on-read in the Bronze layer."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_landing_zone",
   "widgets": {
    "run_date": {
     "currentValue": "2025-12-30",
     "nuid": "e281c13c-d396-458e-b4c7-21f6e819d272",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2026-01-10",
      "label": "Run date",
      "name": "run_date",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2026-01-10",
      "label": "Run date",
      "name": "run_date",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
