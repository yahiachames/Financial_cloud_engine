{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {
                        "byteLimit": 2048000,
                        "rowLimit": 10000
                    },
                    "collapsed": true,
                    "inputWidgets": {},
                    "nuid": "4cbf5bd0-a1bc-49f7-af63-4ca7924db9a5",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "from datetime import datetime , timedelta\n",
                "from pyspark.sql import Window\n",
                "from pyspark.sql.functions import col, lit, input_file_name, current_timestamp,regexp_extract, to_date , lag,explode , from_json , nullif\n",
                "from pyspark.sql.types import ArrayType , StringType , StructField , StructType\n",
                "dbutils.widgets.text(\"start_date\", datetime.now().strftime(\"%Y-%m-%d\"),\"Start date\")\n",
                "dbutils.widgets.text(\"end_date\", datetime.now().strftime(\"%Y-%m-%d\"),\"End date\")\n",
                "\n",
                "dbutils.widgets.text(\"mode\", \"INCREMENTAL\",\"mode\")\n",
                "\n",
                "start_date_str = dbutils.widgets.get(\"start_date\")\n",
                "end_date_str = dbutils.widgets.get(\"end_date\")\n",
                "mode = dbutils.widgets.get(\"mode\")\n",
                "\n",
                "date_format = \"%Y-%m-%d\"\n",
                "\n",
                "start_date = datetime.strptime(start_date_str, date_format).date()\n",
                "end_date = datetime.strptime(end_date_str, date_format).date()\n",
                "\n",
                "if start_date > end_date:\n",
                "    raise ValueError(f\"CRITICAL CONFIG ERROR: Start Date ({start_date}) is after End Date ({end_date}). Please check your parameters.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {
                        "byteLimit": 2048000,
                        "rowLimit": 10000
                    },
                    "inputWidgets": {},
                    "nuid": "eff34b5c-9c0a-46dd-aebf-b3fe2cb294e6",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "ACCESS_KEY = dbutils.secrets.get(scope = \"ticker\", key = \"access_key\")\n",
                "SECRET_KEY = dbutils.secrets.get(scope = \"ticker\", key = \"secret_key\")\n",
                "SESSION_TOKEN = dbutils.secrets.get(scope = \"ticker\", key = \"session_key\")\n",
                "\n",
                "temp_ak = dbutils.jobs.taskValues.get(taskKey=\"Init_Auth\", key=\"temp_ak\", debugValue=\"debug-key\")\n",
                "temp_sk = dbutils.jobs.taskValues.get(taskKey=\"Init_Auth\", key=\"temp_sk\", debugValue=\"debug-secret\")\n",
                "temp_token = dbutils.jobs.taskValues.get(taskKey=\"Init_Auth\", key=\"temp_token\", debugValue=\"debug-token\")\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {
                        "byteLimit": 2048000,
                        "rowLimit": 10000
                    },
                    "inputWidgets": {},
                    "nuid": "ac034a47-c210-47c7-a38d-48bef2036aad",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "def load_df(path , statement , mode):\n",
                "\n",
                "\n",
                "    df_silver = (spark.read\n",
                "        .format(\"delta\")\n",
                "        .option(\"fs.s3a.access.key\", temp_ak)\n",
                "      .option(\"fs.s3a.secret.key\", temp_sk)\n",
                "      .option(\"fs.s3a.session.token\", temp_token)\n",
                "        .option(\"fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider\")\n",
                "        .option(\"mode\" , \"PERMESSIVE\")\n",
                "        .option(\"columnNameOfCorruptRecord\" , \"_rescued_data\")\n",
                "        .load(path + f\"/{statement}\")  # <--- No wildcards, no date=... loops\n",
                "    )\n",
                "\n",
                "    # 2. Apply \"Pushdown Predicate\" (The Filter)\n",
                "    # Spark sends this logic to the Delta Log BEFORE reading data.\n",
                "    if mode == \"INCREMENTAL\":\n",
                "        print(f\"Filtering for range: {start_date} to {end_date}\")\n",
                "        df_silver = df_silver.filter(\n",
                "        (col(\"date\") >= lit(start_date)) & \n",
                "        (col(\"date\") <= lit(end_date))\n",
                "    )\n",
                "\n",
                "    # 3. Verify\n",
                "    df_silver.printSchema()\n",
                "    print(f\"Row Count: {df_silver.count()}\")\n",
                "    return df_silver\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {
                        "byteLimit": 2048000,
                        "rowLimit": 10000
                    },
                    "inputWidgets": {},
                    "nuid": "c96869da-b238-4443-88e4-6ae75ffd363f",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "base_path = \"s3a://mzon-to-databricks-5482/silver/valid\"\n",
                "df_income_statement_silver = load_df(base_path , \"income_statement\" , mode)\n",
                "df_balance_sheet_silver = load_df(base_path , \"balance_sheet\" , mode)\n",
                "df_cashflow_statement_silver = load_df(base_path , \"cashflow_statement\" , mode)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {
                        "byteLimit": 2048000,
                        "rowLimit": 10000
                    },
                    "inputWidgets": {},
                    "nuid": "86f40ce0-15b1-44a1-9ec4-2b967d99a6a8",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "def schema_generator(schema):\n",
                "    schema_modified = schema.add(\"_corrupt_record\", StringType(), True)\n",
                "    json_schema = ArrayType(schema_modified)\n",
                "    return schema_modified , json_schema"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {
                        "byteLimit": 2048000,
                        "rowLimit": 10000
                    },
                    "inputWidgets": {},
                    "nuid": "658b3c2a-8ed4-4247-957a-69a5323cbf57",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "\n",
                "gold_financial_statement_schema = spark.table(\"gold_financial_statement_schema_holder\").schema\n",
                "gold_financial_statement_schema_modified, gold_financial_statement_schema_json = schema_generator(gold_financial_statement_schema)\n",
                "\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {
                        "byteLimit": 2048000,
                        "rowLimit": 10000
                    },
                    "inputWidgets": {},
                    "nuid": "9e9dc570-0e41-45ee-909e-9e9a7849581e",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "df_income_statement_silver.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {
                        "byteLimit": 2048000,
                        "rowLimit": 10000
                    },
                    "inputWidgets": {},
                    "nuid": "7f7cabe1-827e-4860-b7ef-e99b7a37ca2b",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "\n",
                "df_balance_sheet_silver.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {
                        "byteLimit": 2048000,
                        "rowLimit": 10000
                    },
                    "inputWidgets": {},
                    "nuid": "c793e731-f580-44f0-aa9a-0a2e845ded74",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "df_cashflow_statement_silver.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {
                        "byteLimit": 2048000,
                        "rowLimit": 10000
                    },
                    "inputWidgets": {},
                    "nuid": "2b1b3382-b5f2-4222-9484-c6149d1cf9e9",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "df_gold = df_income_statement_silver.join(other=df_balance_sheet_silver , how=\"inner\", on=[\"date\",\"symbol\"]).join(other=df_cashflow_statement_silver , how=\"inner\", on=[\"date\",\"symbol\"])\n",
                "df_gold.printSchema()\n",
                "df_gold.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {
                        "byteLimit": 2048000,
                        "rowLimit": 10000
                    },
                    "inputWidgets": {},
                    "nuid": "02c2746b-4c61-4b5a-9a4d-0756b0b02e96",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "WindowSpec = Window.partitionBy(\"symbol\").orderBy(\"date\")\n",
                "\n",
                "df_gold = (df_gold.withColumn(\"nopat\" , col(\"ebit\") - col(\"incomeTaxExpense\")) \n",
                "           .withColumn(\"gross_margin\" , col(\"grossProfit\") / nullif(col(\"revenue\"),lit(0)))\n",
                "           .withColumn(\"working_capital\",col(\"netReceivables\") + col(\"netReceivables\") - col(\"accountPayables\"))\n",
                "           .withColumn(\"prev_working_capital\" , lag(\"working_capital\",1).over(WindowSpec))\n",
                "           .withColumn(\"delta_wc\" ,col(\"working_capital\") - col(\"prev_working_capital\"))\n",
                "           .withColumn(\"capex\" , col(\"capitalExpenditure\"))\n",
                "           .withColumn(\"reinvestment_rate\",col(\"capex\") / nullif(col(\"ebit\"),lit(0)))\n",
                "           .withColumn(\"depreciation\" , col(\"depreciationAndAmortization\"))\n",
                "           .withColumn(\"net_debt\",col(\"totalDebt\") )\n",
                "           .withColumn(\"liquidity_ratio\", col(\"TotalCurrentAssets\") / nullif(col(\"TotalCurrentLiabilities\"),lit(0)))\n",
                "           .withColumn(\"interest_coverage_ratio\" , col(\"ebit\") / nullif(col(\"interestExpense\"),lit(0)))\n",
                "           .withColumn(\"calculated_fcf\",col(\"nopat\") + col(\"depreciation\") - col(\"delta_wc\") - col(\"capex\") )\n",
                "           \n",
                "           \n",
                "           )\n",
                "df_gold = df_gold.select(\"date\",\"symbol\",\"nopat\",\"gross_margin\",\"revenue\", \"ebit\",\"working_capital\",\"delta_wc\",\"capex\",\"reinvestment_rate\",\"depreciation\",\"net_debt\",\"liquidity_ratio\",\"interest_coverage_ratio\",\"calculated_fcf\",col(\"weightedAverageShsOutDil\").alias(\"shares_outstanding\"),\n",
                "    col(\"interestExpense\").alias(\"interest_expense\"),\n",
                "    col(\"incomeTaxExpense\").alias(\"tax_expense\"),\n",
                "    col(\"totalDebt\").alias(\"total_debt\"))\n",
                "df_gold.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {
                        "byteLimit": 2048000,
                        "rowLimit": 10000
                    },
                    "inputWidgets": {},
                    "nuid": "8af33d30-11d3-4912-8478-d8214858258d",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "from pyspark.sql.functions import col, lit, when, concat_ws,row_number\n",
                "from pyspark.sql import DataFrame\n",
                "from pyspark.sql.types import StructType\n",
                "\n",
                "def align_and_validate_strict(df: DataFrame, target_schema: StructType):\n",
                "    \"\"\"\n",
                "    STRICT VERSION:\n",
                "    - If a column is missing from the input DF, the row is marked BAD (Quarantined).\n",
                "    - If a column exists but has bad data (Type mismatch), the row is marked BAD.\n",
                "    \"\"\"\n",
                "    existing_cols = df.columns\n",
                "    selected_cols = []\n",
                "\n",
                "    for field in target_schema:\n",
                "        if field.name in existing_cols:\n",
                "            selected_cols.append(field.name)\n",
                "        else:\n",
                "            selected_cols.append(lit(None).try_cast(field.dataType).alias(field.name))\n",
                "        \n",
                "    df_aligned = df.select(*selected_cols)\n",
                "    row_validation = []\n",
                "    for field in target_schema:\n",
                "        col_name = field.name\n",
                "        col_type = field.dataType\n",
                "        is_nullable = field.nullable\n",
                "\n",
                "        cast_result = col(col_name).try_cast(col_type).alias(col_name)\n",
                "        if is_nullable:\n",
                "            is_valid_rule = (col(col_name).isNull()) | (cast_result.isNotNull())\n",
                "        else:\n",
                "            is_valid_rule = cast_result.isNotNull()\n",
                "        err_ms = when(~is_valid_rule , lit(col_name)).otherwise(lit(None))\n",
                "        row_validation.append(err_ms)\n",
                "\n",
                "    df_scored = df_aligned.withColumn(\"_failed_cols\" , concat_ws(\",\",*row_validation))\n",
                "    return df_scored\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {
                        "byteLimit": 2048000,
                        "rowLimit": 10000
                    },
                    "inputWidgets": {},
                    "nuid": "211fc53c-b68d-4ee3-a5c9-b230dc70f7d8",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "source": [
                "The function `DeltaTable.isDeltaTable(spark, path)` creates a fresh connection to S3 to check for the `_delta_log` folder.\n",
                "\n",
                "**The Problem**: This new connection does not know about the AWS keys (ACCESS_KEY, etc.) injected into the reader. It attempts an anonymous connection and is rejected by AWS.\n",
                "\n",
                "**The Constraint**: On a Shared Cluster, global keys (`spark.conf.set`) are banned, making DeltaTable utilities effectively absent."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {
                        "byteLimit": 2048000,
                        "rowLimit": 10000
                    },
                    "inputWidgets": {},
                    "nuid": "a8efdce8-a2aa-4aaa-b9c6-1f89c341f6fc",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "def clean_df(df):\n",
                "    df_deduplicated = df\n",
                "    window_spec = Window.partitionBy(\"symbol\",\"date\") \\\n",
                "                        .orderBy(col(\"date\").desc())\n",
                "    df_deduplicated = df_deduplicated.withColumn(\"_rank\", row_number().over(window_spec)) \\\n",
                "                                    .filter(col(\"_rank\") == \"1\") \\\n",
                "                                    .drop(\"_rank\")\n",
                "    return df_deduplicated\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {
                        "byteLimit": 2048000,
                        "rowLimit": 10000
                    },
                    "inputWidgets": {},
                    "nuid": "f126b358-5d31-406d-8ae9-747f92ed8aa1",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "def validate_df(df,schema):\n",
                "    df_evaluated = align_and_validate_strict(df, schema)\n",
                "    #PERSIST TABLE is not supported on serverless compute. SQLSTATE: 0A000\n",
                "    #df_evaluated.cache()\n",
                "    valid_records = df_evaluated.filter(col(\"_failed_cols\") == \"\").drop(\"_failed_cols\")\n",
                "    invalid_records = df_evaluated.filter((col(\"_failed_cols\") != \"\") | (col(\"_corrupt_record\").isNotNull()) )\n",
                "    # df_evaluated.unpersist()\n",
                "    return valid_records, invalid_records\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {
                        "byteLimit": 2048000,
                        "rowLimit": 10000
                    },
                    "inputWidgets": {},
                    "nuid": "a4fcb1b1-8c36-45c3-aefc-5744d96a0c1f",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "\n",
                "\n",
                "df_gold_cleaned = clean_df(df_gold) \n",
                "df_gold_cleaned.show()\n",
                "df_gold_valid_records, df_gold_invalid_records = validate_df(df_gold_cleaned,gold_financial_statement_schema_modified)\n",
                "\n",
                "df_gold_valid_records.show()\n",
                "\n",
                "df_gold_invalid_records.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {},
                    "inputWidgets": {},
                    "nuid": "554f0480-9f8d-4a7f-97e0-88cf9b41b0e5",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "source": [
                "### Write Strategy: Credential-Injection Overwrite\n",
                "\n",
                "We use **Overwrite by Partition** with a `replaceWhere` condition. This achieves Idempotency while allowing us to explicitly pass the `fs.s3a.access.key` credentials in the `.write` options, bypassing the need for an Instance Profile."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {
                        "byteLimit": 2048000,
                        "rowLimit": 10000
                    },
                    "inputWidgets": {},
                    "nuid": "8670305b-03b0-405b-a35f-91fbbb27cf8c",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "def write_df(df,label,path,mode):\n",
                "    if mode == \"INCREMENTAL\" : \n",
                "            (df.write\n",
                "            .format(\"delta\")\n",
                "            .mode(\"overwrite\")\n",
                "            .partitionBy(\"date\")\n",
                "            # CRITICAL: This condition ensures we only overwrite the partitions present in the current batch\n",
                "            .option(\"replaceWhere\", f\"date >= '{start_date}' AND date <= '{end_date}'\")\n",
                "            # INJECT CREDENTIALS AGAIN (Required for the Writer)\n",
                "            .option(\"fs.s3a.access.key\", temp_ak)\n",
                "            .option(\"fs.s3a.secret.key\", temp_sk)\n",
                "            .option(\"fs.s3a.session.token\", temp_token)\n",
                "            .option(\"fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider\")\n",
                "\n",
                "            .save(path + f\"/{label}\"))\n",
                "    else:\n",
                "        (df.write\n",
                "        .format(\"delta\")\n",
                "        .mode(\"overwrite\")\n",
                "        .partitionBy(\"date\")\n",
                "        # INJECT CREDENTIALS AGAIN (Required for the Writer)\n",
                "       .option(\"fs.s3a.access.key\", temp_ak)\n",
                "      .option(\"fs.s3a.secret.key\", temp_sk)\n",
                "      .option(\"fs.s3a.session.token\", temp_token)\n",
                "        .option(\"fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider\")\n",
                "        .option(\"overwriteSchema\", \"true\")\n",
                "        .save(path + f\"/{label}\")\n",
                "    )\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {
                        "byteLimit": 2048000,
                        "rowLimit": 10000
                    },
                    "inputWidgets": {},
                    "nuid": "ad465dcc-770b-41d2-9688-7964164f2797",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "df_gold_valid_records.printSchema()\n",
                "df_gold_valid_records.show()\n",
                "bronze_path_invalid = \"s3a://mzon-to-databricks-5482/gold\"\n",
                "write_df(df_gold_valid_records,\"valid\",bronze_path_invalid,mode)\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {
                        "byteLimit": 2048000,
                        "rowLimit": 10000
                    },
                    "inputWidgets": {},
                    "nuid": "c0be4b4b-2988-4d4d-b08e-ec56558ace98",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "df_gold_invalid_records.printSchema()\n",
                "df_gold_invalid_records.show()\n",
                "bronze_path_invalid = \"s3a://mzon-to-databricks-5482/gold\"\n",
                "write_df(df_gold_invalid_records,\"invalid\",bronze_path_invalid,\"FULL\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {
                        "byteLimit": 2048000,
                        "rowLimit": 10000
                    },
                    "inputWidgets": {},
                    "nuid": "3f80b9aa-d432-4543-9f25-db2d96ed4637",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "print(df_gold_valid_records.count() / (df_gold_invalid_records.count() + df_gold_valid_records.count()))\n",
                " "
            ]
        }
    ],
    "metadata": {
        "application/vnd.databricks.v1+notebook": {
            "computePreferences": null,
            "dashboards": [],
            "environmentMetadata": {
                "base_environment": "",
                "environment_version": "4"
            },
            "inputWidgetPreferences": null,
            "language": "python",
            "notebookMetadata": {
                "mostRecentlyExecutedCommandWithImplicitDF": {
                    "commandId": 3399404293038751,
                    "dataframes": [
                        "_sqldf"
                    ]
                },
                "pythonIndentUnit": 4
            },
            "notebookName": "gold_financials_batch",
            "widgets": {
                "end_date": {
                    "currentValue": "2025-12-25",
                    "nuid": "3e3ccc72-64ca-4c2f-acee-a9b778d60a92",
                    "typedWidgetInfo": {
                        "autoCreated": false,
                        "defaultValue": "2026-01-10",
                        "label": "End date",
                        "name": "end_date",
                        "options": {
                            "widgetDisplayType": "Text",
                            "validationRegex": null
                        },
                        "parameterDataType": "String"
                    },
                    "widgetInfo": {
                        "widgetType": "text",
                        "defaultValue": "2026-01-10",
                        "label": "End date",
                        "name": "end_date",
                        "options": {
                            "widgetType": "text",
                            "autoCreated": null,
                            "validationRegex": null
                        },
                        "widgetType": "text"
                    }
                },
                "mode": {
                    "currentValue": "FULL",
                    "nuid": "a47ce8d2-bdd3-4572-a4d5-620a4b711fc3",
                    "typedWidgetInfo": {
                        "autoCreated": false,
                        "defaultValue": "INCREMENTAL",
                        "label": "mode",
                        "name": "mode",
                        "options": {
                            "widgetDisplayType": "Text",
                            "validationRegex": null
                        },
                        "parameterDataType": "String"
                    },
                    "widgetInfo": {
                        "widgetType": "text",
                        "defaultValue": "INCREMENTAL",
                        "label": "mode",
                        "name": "mode",
                        "options": {
                            "widgetType": "text",
                            "autoCreated": null,
                            "validationRegex": null
                        },
                        "widgetType": "text"
                    }
                },
                "start_date": {
                    "currentValue": "2025-12-25",
                    "nuid": "52c48461-d4bc-4618-ac4b-8606cbd25cf8",
                    "typedWidgetInfo": {
                        "autoCreated": false,
                        "defaultValue": "2026-01-10",
                        "label": "Start date",
                        "name": "start_date",
                        "options": {
                            "widgetDisplayType": "Text",
                            "validationRegex": null
                        },
                        "parameterDataType": "String"
                    },
                    "widgetInfo": {
                        "widgetType": "text",
                        "defaultValue": "2026-01-10",
                        "label": "Start date",
                        "name": "start_date",
                        "options": {
                            "widgetType": "text",
                            "autoCreated": null,
                            "validationRegex": null
                        },
                        "widgetType": "text"
                    }
                }
            }
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}