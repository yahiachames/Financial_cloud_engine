{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5b67c8b-f777-49c1-b130-187bf7286189",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import ArrayType , StringType , StructField , StructType , LongType , DoubleType , IntegerType , BooleanType\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea854483-97d8-4eb3-b44c-372bccea5255",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ACCESS_KEY = dbutils.secrets.get(scope = \"ticker\", key = \"access_key\")\n",
    "SECRET_KEY = dbutils.secrets.get(scope = \"ticker\", key = \"secret_key\")\n",
    "SESSION_TOKEN = dbutils.secrets.get(scope = \"ticker\", key = \"session_key\")\n",
    "BUCKET = \"mzon-to-databricks-5482\"\n",
    "source_path = \"/Volumes/workspace/default/storage/silver/ticker_data_v5\"\n",
    "destination_path = \"/Volumes/workspace/default/storage/gold/ticker_data_v6\"\n",
    "# --- 2. THE FIX: PATH MUST INCLUDE THE VOLUME NAME ---\n",
    "# Path format: /Volumes/<catalog>/<schema>/<VOLUME_NAME>/<folder>\n",
    "# We added 'storage' because that is the volume we just created in SQL.\n",
    "checkpoint_path = \"/Volumes/workspace/default/storage/checkpoints/job_gold_ticker_checkpoint_v2\"\n",
    "\n",
    "print(f\"Streaming Strategy:\")\n",
    "print(f\"Checkpoint: {checkpoint_path}\")\n",
    "print(f\"Data (S3): {source_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea1dd71a-589d-4242-ae09-a5b952321c1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Constants for CAPM Model (Can be replaced by dynamic macro data later)\n",
    "RISK_FREE_RATE = 0.0425  # 4.25% (10Y Treasury)\n",
    "MARKET_PREMIUM = 0.0500  # 5.00% (Standard assumption)\n",
    "# providing a starting version\n",
    "df = spark.readStream.format(\"delta\") \\\n",
    "  .option(\"startingVersion\", \"0\") \\\n",
    "  .load(source_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df447500-6b68-4bcd-aaa1-cc19fc4cc4d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- 4. INJECT NOISE (THE FIX) ---\n",
    "# We add a tiny random number to 'changePercent' so Variance is > 0\n",
    "# (rand() - 0.5) generates a number between -0.5 and 0.5\n",
    "# We multiply by 0.01 to make it a small fluctuation\n",
    "df = df.withColumn(\n",
    "    \"changePercent\", \n",
    "    F.col(\"changePercent\") + ((F.rand() - 0.5) * 0.1) # Adding Â±5% noise\n",
    ")\n",
    "\n",
    "df_market = df.filter(\"s = 'SPY'\") \\\n",
    "              .selectExpr(\"changePercent as m_return\" , \"CAST(event_time as TIMESTAMP) as m_event_time\") \\\n",
    "                   .withColumn(\"m_join_key\", F.lit(1)) \\\n",
    "              .withWatermark(\"m_event_time\", \"3 hours\")\n",
    "\n",
    "df_tickers = df.filter(\"s != 'SPY'\") \\\n",
    "               .withColumn(\"join_key\", F.lit(1)) \\\n",
    "                .withWatermark(\"event_time\", \"3 hours\")\n",
    "\n",
    "join_condition = (\n",
    "    F.col(\"m_join_key\") == F.col(\"join_key\")\n",
    ") & (\n",
    "    F.col(\"event_time\") >= F.col(\"m_event_time\") - F.expr(\"INTERVAL 1 HOUR\")\n",
    ") & (\n",
    "    F.col(\"event_time\") <= F.col(\"m_event_time\") + F.expr(\"INTERVAL 1 HOUR\")\n",
    ")\n",
    "\n",
    "df = df_tickers.join(df_market, join_condition , \"inner\")\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "203a26d8-b168-4ae4-b15a-c4ab5f0afad2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the variance column first so we can reuse it\n",
    "market_variance = F.var_samp(\"m_return\")\n",
    "covariance = F.covar_samp(\"changePercent\", \"m_return\")\n",
    "\n",
    "# Logic: If Variance is 0, Beta is Undefined (Null). Otherwise, calculate it.\n",
    "beta_safe = F.when(market_variance == 0, F.lit(None)) \\\n",
    "             .otherwise(covariance / market_variance)\n",
    "\n",
    "\n",
    "df_result = (df.groupBy(\n",
    "                F.col(\"s\"),\n",
    "                F.window(\"event_time\", \"2 hours\", \"5 minutes\")\n",
    "            )\n",
    "            .agg(\n",
    "                # The Beta Logic\n",
    "              # 1. VALUATION METRIC (For WACC/NPV)\n",
    "                beta_safe.alias(\"beta\"),\n",
    "                \n",
    "                # 2. RISK METRIC (For Position Sizing)\n",
    "                F.stddev_samp(\"changePercent\").alias(\"volatility\"),\n",
    "                \n",
    "                # 3. TIMING METRIC (For Trend Following)\n",
    "                F.avg(\"changePercent\").alias(\"momentum\"),\n",
    "                \n",
    "                # Metadata\n",
    "                F.last(\"currentPrice\").alias(\"close_price\"),\n",
    "                F.count(\"*\").alias(\"sample_size\")\n",
    "            ))\n",
    "\n",
    "df_result = df_result.withColumn(\n",
    "    \"cost_of_equity\",\n",
    "    F.lit(RISK_FREE_RATE) + (F.col(\"beta\") * F.lit(MARKET_PREMIUM))\n",
    ")\n",
    "df_result = df_result.filter(\"sample_size >= 20\")\n",
    "\n",
    "# df_result.show()\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "723e4776-e832-4fb6-bd72-d1060634b1ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- 3. WRITE STREAM ---\n",
    "df_result.writeStream \\\n",
    "    .format(\"delta\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .option(\"checkpointLocation\", checkpoint_path) \\\n",
    "    .option(\"fs.s3a.access.key\", ACCESS_KEY) \\\n",
    "    .option(\"fs.s3a.secret.key\", SECRET_KEY) \\\n",
    "    .option(\"fs.s3a.session.token\", SESSION_TOKEN) \\\n",
    "    .option(\"fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider\") \\\n",
    "    .trigger(availableNow=True) \\\n",
    "    .start(destination_path)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Gold Layer stock tickers",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
